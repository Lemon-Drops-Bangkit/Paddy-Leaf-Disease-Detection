{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e70c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\syahr\\anaconda3\\lib\\site-packages (1.5.12)\n",
      "Requirement already satisfied: tqdm in c:\\users\\syahr\\anaconda3\\lib\\site-packages (from kaggle) (4.59.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\syahr\\anaconda3\\lib\\site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\syahr\\anaconda3\\lib\\site-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: requests in c:\\users\\syahr\\anaconda3\\lib\\site-packages (from kaggle) (2.25.1)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\syahr\\anaconda3\\lib\\site-packages (from kaggle) (1.26.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\syahr\\anaconda3\\lib\\site-packages (from kaggle) (2020.12.5)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\syahr\\anaconda3\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\syahr\\anaconda3\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\syahr\\anaconda3\\lib\\site-packages (from requests->kaggle) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\syahr\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.10)\n",
      "Requirement already satisfied: patool in c:\\users\\syahr\\anaconda3\\lib\\site-packages (1.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n",
    "!pip install patool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90dd70c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import shuffle\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import patoolib\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aab9642b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base URL : C:\\Users\\syahr\\Documents\\Capstone\n",
      "riceleafs.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "rice-leaf-diseases.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "rice-diseases-image-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "# [READ IT] before you download the dataset, place kaggle.json in the location ~/.kaggle/kaggle.json\n",
    "base_path = os.getcwd()\n",
    "print(\"Base URL :\", base_path)\n",
    "\n",
    "# download riceleafs dataset from https://www.kaggle.com/shayanriyaz/riceleafs\n",
    "#!kaggle datasets download shayanriyaz/riceleafs --force\n",
    "!kaggle datasets download shayanriyaz/riceleafs\n",
    "# download rice-leaf-diseases dataset from https://www.kaggle.com/vbookshelf/rice-leaf-diseases\n",
    "#!kaggle datasets download vbookshelf/rice-leaf-diseases --force\n",
    "!kaggle datasets download vbookshelf/rice-leaf-diseases\n",
    "# download RiceDiseaseDataset dataset from https://www.kaggle.com/minhhuy2810/rice-diseases-image-dataset\n",
    "#!kaggle datasets download minhhuy2810/rice-diseases-image-dataset --force\n",
    "!kaggle datasets download minhhuy2810/rice-diseases-image-dataset\n",
    "\n",
    "# extract riceleafs dataset\n",
    "#patoolib.extract_archive(\"riceleafs.zip\", outdir=base_path)\n",
    "# extract rice-leaf-diseases dataset\n",
    "#patoolib.extract_archive(\"rice-leaf-diseases.zip\", outdir=base_path)\n",
    "# extract RiceDiseaseDataset dataset\n",
    "#patoolib.extract_archive(\"rice-diseases-image-dataset.zip\", outdir=base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5090906",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Helper functions\"\"\"\n",
    "def create_directory(path):\n",
    "    if os.path.exists(path):\n",
    "        print(\"Deleting Directory\", path)\n",
    "        shutil.rmtree(path)\n",
    "        os.makedirs(path)\n",
    "        print(\"Directory\", path,  \"Created \")\n",
    "    elif not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(\"Directory\", path,  \"Created \")\n",
    "\n",
    "def copy_file(list, curr, output):\n",
    "    for file in list:\n",
    "        file_path = curr + \"/\" + file\n",
    "        shutil.copy(file_path, output)  \n",
    "    \n",
    "def get_randomize_list_from_dir(path):\n",
    "    all_files = os.listdir(path)\n",
    "    shuffle(all_files)\n",
    "    return all_files\n",
    "\n",
    "def get_file_list_from_dir(path):\n",
    "    all_files = os.listdir(path)\n",
    "    return all_files\n",
    "\n",
    "def splitting(file_list):\n",
    "    split = 0.7\n",
    "    split_index = floor(len(file_list) * split)\n",
    "    training = file_list[:split_index]\n",
    "    testing = file_list[split_index:]\n",
    "    return training, testing\n",
    "\n",
    "def split_train_val(path, label):\n",
    "    output_train = path.rsplit('/', 1)[-2] + '/train/' + label\n",
    "    output_validation = path.rsplit('/', 1)[-2] + '/validation/' + label\n",
    "\n",
    "    create_directory(output_train)\n",
    "    create_directory(output_validation)\n",
    "\n",
    "    get_file = get_file_list_from_dir(path)\n",
    "    list_train_file = splitting(get_file)[0]\n",
    "    list_validation_file = splitting(get_file)[1]\n",
    "\n",
    "    copy_file(list_train_file, path, output_train)\n",
    "    copy_file(list_validation_file, path, output_validation)\n",
    "\n",
    "def resize(input_path, size):\n",
    "    dirs = os.listdir(input_path)\n",
    "    for item in dirs:\n",
    "        item_path = input_path + '/' + item\n",
    "        if os.path.isfile(item_path):\n",
    "            #print('CHECK')\n",
    "            im = Image.open(item_path)\n",
    "\n",
    "            # Check whether the specified \n",
    "            # path exists or not \n",
    "            outpath = input_path\n",
    "            temp_out_path = outpath + '/' + item\n",
    "            name, e = os.path.splitext(temp_out_path)\n",
    "\n",
    "            imResize = im.resize(size, Image.ANTIALIAS)\n",
    "            #print('CHECK 3')\n",
    "            imResize.save(name + '.jpg', 'JPEG', quality=90)\n",
    "\n",
    "def count(path):\n",
    "    counts = 0\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:    \n",
    "            counts += 1\n",
    "    return counts\n",
    "\n",
    "def merge_data(data, path, label, author):\n",
    "    if data == \"train\":\n",
    "        out_dir = out_dir_train\n",
    "    elif data == \"validation\":\n",
    "        out_dir = out_dir_validation\n",
    "    else:\n",
    "        print(\"Wrong outdir\")\n",
    "    get_file = get_file_list_from_dir(path)\n",
    "    for file in get_file:\n",
    "        if not os.path.exists(out_dir + \"/\" + label + \"/\" + author + \"_\" + file):\n",
    "            file_path = path + \"/\" + file\n",
    "            shutil.copy(file_path, out_dir + \"/\" + label)\n",
    "            os.rename(out_dir + \"/\" + label + \"/\" + file, out_dir + \"/\" + label + \"/\" + author + \"_\" + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4899b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to rice-leaf-diseases dataset from https://www.kaggle.com/vbookshelf/rice-leaf-diseases\n",
    "vbookshelf_img = base_path + '/rice_leaf_diseases'\n",
    "\n",
    "# path to LabelledRice dataset from https://www.kaggle.com/minhhuy2810/rice-diseases-image-dataset\n",
    "labelledrice_img = base_path + '/LabelledRice/Labelled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1deb934a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory C:\\Users\\syahr\\Documents\\Capstone/rice_leaf_diseases/train/Bacterial_Leaf_Blight Created \n",
      "Directory C:\\Users\\syahr\\Documents\\Capstone/rice_leaf_diseases/validation/Bacterial_Leaf_Blight Created \n",
      "Directory C:\\Users\\syahr\\Documents\\Capstone/rice_leaf_diseases/train/Leaf_Smut Created \n",
      "Directory C:\\Users\\syahr\\Documents\\Capstone/rice_leaf_diseases/validation/Leaf_Smut Created \n",
      "Deleting Directory C:\\Users\\syahr\\Documents\\Capstone/rice_leaf_diseases/train/Brown_Spot\n",
      "Directory C:\\Users\\syahr\\Documents\\Capstone/rice_leaf_diseases/train/Brown_Spot Created \n",
      "Deleting Directory C:\\Users\\syahr\\Documents\\Capstone/rice_leaf_diseases/validation/Brown_Spot\n",
      "Directory C:\\Users\\syahr\\Documents\\Capstone/rice_leaf_diseases/validation/Brown_Spot Created \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# since these LabelledRice dataset don\\'t have validation dataset, split into train/validation\\nlabel = [\"Brown_Spot\", \"Healthy\", \"Hispa\", \"Leaf_Blast\"]\\nlabel_path = {\\n    \"Brown_Spot\": labelledrice_img + \"/BrownSpot\",\\n    \"Healthy\": labelledrice_img + \"/Healthy\",\\n    \"Hispa\": labelledrice_img + \"/Hispa\",\\n    \"Leaf_Blast\": labelledrice_img + \"/LeafBlast\"\\n}\\n\\nfor x in label:\\n    split_train_val(label_path[x], x)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since these rice-leaf-diseases dataset don't have validation dataset, split into train/validation\n",
    "#label = [\"Brown_Spot\"]\n",
    "label = [\"Brown_Spot\"]\n",
    "label_path = {\n",
    "    \"Bacterial_Leaf_Blight\": vbookshelf_img + \"/Bacterial leaf blight\",\n",
    "    \"Leaf_Smut\": vbookshelf_img + \"/Leaf smut\",\n",
    "    \"Brown_Spot\": vbookshelf_img + \"/Brown spot\"\n",
    "}\n",
    "\n",
    "for x in label:\n",
    "    split_train_val(label_path[x], x)\n",
    "    \n",
    "# since these LabelledRice dataset don't have validation dataset, split into train/validation\n",
    "label = [\"Brown_Spot\", \"Healthy\", \"Hispa\", \"Leaf_Blast\"]\n",
    "label_path = {\n",
    "    \"Brown_Spot\": labelledrice_img + \"/BrownSpot\",\n",
    "    \"Healthy\": labelledrice_img + \"/Healthy\",\n",
    "    \"Hispa\": labelledrice_img + \"/Hispa\",\n",
    "    \"Leaf_Blast\": labelledrice_img + \"/LeafBlast\"\n",
    "}\n",
    "\n",
    "for x in label:\n",
    "    split_train_val(label_path[x], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b7f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to riceleafs dataset from https://www.kaggle.com/shayanriyaz/riceleafs\n",
    "shayanriyaz_train = base_path + '/RiceLeafs/train' \n",
    "shayanriyaz_validation = base_path + '/RiceLeafs/validation'\n",
    "\n",
    "# path to rice-leaf-diseases dataset from https://www.kaggle.com/vbookshelf/rice-leaf-diseases\n",
    "vbookshelf_train = base_path + '/rice_leaf_diseases/train'\n",
    "vbookshelf_validation = base_path + '/rice_leaf_diseases/validation'\n",
    "\n",
    "# path to RiceDiseaseDataset dataset from https://www.kaggle.com/minhhuy2810/rice-diseases-image-dataset\n",
    "minhhuy2810_train = base_path + '/RiceDiseaseDataset/train' \n",
    "minhhuy2810_validation = base_path + '/RiceDiseaseDataset/validation'\n",
    "\n",
    "# path to LabelledRice dataset from https://www.kaggle.com/minhhuy2810/rice-diseases-image-dataset\n",
    "labelledrice_train = base_path + '/LabelledRice/Labelled/train'\n",
    "labelledrice_validation = base_path + '/LabelledRice/Labelled/validation'\n",
    "\n",
    "# Create target directory & all intermediate directories if don't exists\n",
    "column_names = ['Brown_Spot', 'Healthy', 'Hispa', 'Leaf_Blast']\n",
    "out_dir_train = 'data/train'\n",
    "out_dir_validation = 'data/validation'\n",
    "\n",
    "for i in column_names:\n",
    "    create_directory(out_dir_train + \"/{}\".format(i))\n",
    "    create_directory(out_dir_validation + \"/{}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4fb11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting files on training/validation dataset\n",
    "author = [\"shayanriyaz\", \"vbookshelf\", \"minhhuy2810\", \"labelledrice\"]\n",
    "author_path_train = {\n",
    "    \"shayanriyaz\": shayanriyaz_train,\n",
    "    \"vbookshelf\": vbookshelf_train,\n",
    "    \"minhhuy2810\": minhhuy2810_train,\n",
    "    \"labelledrice\": labelledrice_train\n",
    "}\n",
    "author_path_validation = {\n",
    "    \"shayanriyaz\": shayanriyaz_validation,\n",
    "    \"vbookshelf\": vbookshelf_validation,\n",
    "    \"minhhuy2810\": minhhuy2810_validation,\n",
    "    \"labelledrice\": labelledrice_validation\n",
    "}\n",
    "\n",
    "total_train = 0\n",
    "for x in author:\n",
    "    print(\"Total files Training Dataset in {}\".format(x), count(author_path_train[x]))\n",
    "    total_train += count(author_path_train[x])\n",
    "\n",
    "total_validation = 0\n",
    "for x in author:\n",
    "    print(\"Total files Validation Dataset in {}\".format(x), count(author_path_validation[x]))\n",
    "    total_validation += count(author_path_validation[x])\n",
    "\n",
    "print(\"Total files in Training Dataset\", total_train)\n",
    "print(\"Total files in Validation\", total_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8550e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all train/validation dataset\n",
    "author = [[\"shayanriyaz\", \"minhhuy2810\"], [\"vbookshelf\", \"labelledrice\"]]\n",
    "data = [\"train\", \"validation\"]\n",
    "label = [\"Brown_Spot\", \"Healthy\", \"Hispa\", \"Leaf_Blast\"]\n",
    "\n",
    "for x in author[0]:\n",
    "    label_path = {\n",
    "        \"Brown_Spot\": \"/BrownSpot\",\n",
    "        \"Healthy\": \"/Healthy\",\n",
    "        \"Hispa\": \"/Hispa\",\n",
    "        \"Leaf_Blast\": \"/LeafBlast\"\n",
    "    }\n",
    "    for y in data:\n",
    "        for z in label:\n",
    "            if x == \"shayanriyaz\":\n",
    "                if y == \"train\":\n",
    "                    path = shayanriyaz_train\n",
    "                elif y == \"validation\":\n",
    "                    path = shayanriyaz_validation\n",
    "                else:\n",
    "                    print(\"Wrong path\")\n",
    "            elif x == \"minhhuy2810\":\n",
    "                if y == \"train\":\n",
    "                    path = minhhuy2810_train\n",
    "                elif y == \"validation\":\n",
    "                    path = minhhuy2810_validation\n",
    "                else:\n",
    "                    print(\"Wrong path\")\n",
    "            else:\n",
    "                print(\"Wrong path\")\n",
    "            merge_data(y, path + label_path[z], z, x)\n",
    "\n",
    "for x in author[1]:\n",
    "    label_path = {\n",
    "        \"Brown_Spot\": \"/Brown_Spot\",\n",
    "        \"Healthy\": \"/Healthy\",\n",
    "        \"Hispa\": \"/Hispa\",\n",
    "        \"Leaf_Blast\": \"/Leaf_Blast\"\n",
    "    }\n",
    "    for y in data:\n",
    "        if x == \"vbookshelf\":\n",
    "            label = [\"Brown_Spot\"]\n",
    "        elif x == \"labelledrice\":\n",
    "            label = [\"Brown_Spot\", \"Healthy\", \"Hispa\", \"Leaf_Blast\"]\n",
    "        else:\n",
    "            print(\"Wrong label\")\n",
    "        for z in label:\n",
    "            if x == \"vbookshelf\":\n",
    "                if y == \"train\":\n",
    "                    path = vbookshelf_train\n",
    "                elif y == \"validation\":\n",
    "                    path = vbookshelf_validation\n",
    "                else:\n",
    "                    print(\"Wrong path\")\n",
    "            elif x == \"labelledrice\":\n",
    "                if y == \"train\":\n",
    "                    path = labelledrice_train\n",
    "                elif y == \"validation\":\n",
    "                    path = labelledrice_validation\n",
    "                else:\n",
    "                    print(\"Wrong path\")\n",
    "            else:\n",
    "                print(\"Wrong path\")\n",
    "            merge_data(y, path + label_path[z], z, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc21b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CONDITIONAL] resize dataset\n",
    "'''\n",
    "label = [\"Brown_Spot\", \"Healthy\", \"Hispa\", \"Leaf_Blast\"]\n",
    "split = [\"train\", \"validation\"]\n",
    "\n",
    "size = (224,224)\n",
    "\n",
    "for x in split:\n",
    "    for y in label:\n",
    "        input_path = 'data/{}/{}'.format(x, y)\n",
    "        resize(input_path, size)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f222e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting files on training/validation dataset after merging\n",
    "label = [\"Brown_Spot\", \"Healthy\", \"Hispa\", \"Leaf_Blast\"]\n",
    "label_path_train = {\n",
    "    \"Brown_Spot\": 'data/train/Brown_Spot',\n",
    "    \"Healthy\": 'data/train/Healthy',\n",
    "    \"Hispa\": 'data/train/Hispa',\n",
    "    \"Leaf_Blast\": 'data/train/Leaf_Blast'\n",
    "}\n",
    "label_path_validation = {\n",
    "    \"Brown_Spot\": 'data/validation/Brown_Spot',\n",
    "    \"Healthy\": 'data/validation/Healthy',\n",
    "    \"Hispa\": 'data/validation/Hispa',\n",
    "    \"Leaf_Blast\": 'data/validation/Leaf_Blast'\n",
    "}\n",
    "\n",
    "total_train = 0\n",
    "for x in label:\n",
    "    print(\"Total files Training Dataset in {}\".format(x), count(label_path_train[x]))\n",
    "    total_train += count(label_path_train[x])\n",
    "\n",
    "total_validation = 0\n",
    "for x in label:\n",
    "    print(\"Total files Validation Dataset in {}\".format(x), count(label_path_validation[x]))\n",
    "    total_validation += count(label_path_validation[x])\n",
    "\n",
    "print(\"Total files in Training Dataset\", total_train)\n",
    "print(\"Total files in Validation\", total_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe60020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
